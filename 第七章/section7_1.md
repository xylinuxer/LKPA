## 7.1 临界区和竞争状态

&emsp;&emsp;所谓临界区（critical regions）就是访问和操作共享数据的代码段。多个内核任务并发访问同一个资源通常是不安全的。为了避免对临界区进行并发访问，编程者必须保证临界区代码被原子地执行。也就是说，代码在执行期间不可被打断，就如同整个临界区是一个不可分割的指令一样。如果两个内核任务处于同一个临界区中，这就是一种错误现象。如果这种情况确实发生了，我们就称它是竞争状态。注意竞争状态是小概率事件，因为竞争引起的错误有时出现，有时并不出现，所以调试这种错误会非常困难。避免并发和防止竞争状态则称为同步（synchronization）。

### 7.1.1临界区举例

&emsp;&emsp;为了进一步了解竞争状态，我们首先要明白临界区无处不在。首先，我们考虑一个非常简单的共享资源的例子：一个全局整型变量和一个简单的临界区，其中的操作仅仅是将整型变量的值增加1：

&emsp;&emsp;i++;

&emsp;&emsp;该操作可以转化成下面三条机器指令序列：

（1） 得到当前变量i的值并且拷贝到一个寄存器中。

（2）将寄存器中的值加1。

（3） 把i的新值写回到内存中。

&emsp;&emsp;这三条指令形成一个临界区。现在假定有两个内核任务同时进入这个临界区，如果i的初始值是1，那么，我们所期望的结果应该像下面这样：

| **内核任务1** | **内核任务2** |
| --- | --- |
| 获得i（1） | --- |
|  |  |
| 增加 i（1-&gt;2） | --- |
|  |  |
| 写回 i（2） | --- |
|  |  |
|  | 获得 i（2） |
|  |  |
|  | 增加 i（2-&gt;3） |
|  |  |
|  | 写回 i（3） |

&emsp;&emsp;从中可以看出，两个任务分别把i加1，因此i变为3。但是，实际的执行序列却可能如下：

| **内核任务1** | **内核任务2** |
| --- | --- |
| 获得 i（1） | --- |
|  |  |
| --- | 获得 i（1） |
|  |  |
| 增加 i（1-&gt;2） | --- |
|  |  |
| --- | 增加 i（1-&gt;2） |
|  |  |
| 写回 i（2） | --- |
|  |  |
| --- | 写回 i（2） |

&emsp;&emsp;如果两个内核任务都在变量i值增加前读取了它的初值，进而又分别增加变量i的值，最后再保存该值，那么变量i的值就变成了2，也就是说出现了“1+1+1=2”的情况。这是最简单的临界区例子，幸好对这种简单竞争状态的解决方法也同样简单，我们仅仅需要将这些指令作为一个不可分割的整体来执行就可以了。多数处理器都提供了指令来原子地读变量、增加变量然后再写回变量，使用这样的指令就能解决一些问题。内核也提供了一组实现这些原子操作的接口，将在7.2.1节讨论。

### 7.1.2 共享队列和加锁

&emsp;&emsp;现在我们来讨论一个更为复杂的竞争状态。假设有一个需要处理的请求队列，这里假定该队列是一个链表，链表中每个结点的逻辑意义代表一个“请求”。有两个函数可以用来操作此队列：一个函数将新请求添加到队列尾部，另一个函数从队列头删除请求，然后处理它。内核各个部分都会调用这两个函数，所以内核会频繁地在队列中加入请求，从队列中删除请求并对其处理。对请求队列的操作无疑要用多条指令。如果一个任务试图读取队列，而这时正好另一个任务正在处理该队列，那么读取任务就会发现队列此刻正处于不一致状态（与原本要读取的队列不一样了）。很明显，如果允许并发访问队列，就会产生意想不到的错误。当共享资源是一个复杂的数据结构时，竞争状态往往会使该数据结构遭到破坏。

&emsp;&emsp;对于这种情况，锁机制可以避免竞争状态。这种锁就如同一把门锁，门后的房间可想象成一个临界区。在一个指定时间内，房间里只能有个一个内核任务存在，当一个任务进入房间后，它会锁住身后的房门；当它结束对共享数据的操作后，就会走出房间，打开门锁。如果另一个任务在房门上锁时来了,那么它就必须等待房间内的任务出来并打开门锁后，才能进入房间。

&emsp;&emsp;前面例子中讲到的请求队列，可以使用一个单独的锁进行保护。每当有一个新请求要加入队列，任务会首先要占住锁，然后就可以安全地将请求加入到队列中，结束操作后再释放该锁；同样当一个任务想从请求队列中删除一个请求时，也需要先占住锁，然后才能从队列中读取和删除请求，而且在完成操作后也必须释放锁。任何要访问队列的其它任务也类似，必须占住锁后才能进行操作。因为在一个时刻只能有一个任务持有锁，所以在一个时刻只有一个任务可以操作队列。由此可见锁机制可以防止并发执行，并且保护队列不受竞争状态影响。

&emsp;&emsp;任何要访问队列的代码首先都需要占住相应的锁，这样该锁就能阻止来自其它内核任务的并发访问：

| **任务 1** | **任务2** |
| --- | --- |
| 试图锁定队列 | 试图锁定队列 |
|  |  |
| 成功：获得锁 | 失败：等待… |
|  |  |
| 访问队列… | 等待… |
|  |  |
| 为队列解除锁 | 等待… |
|  |  |
| … | 成功：获得锁 |
|  |  |
|  | 访问队列… |
|  |  |
|  | 为队列解除锁 |

&emsp;&emsp;请注意锁的使用是 **自愿的、非强制的**，它完全属于一种编程者自选的编程手段。当然，如果不这么做，无疑会造成竞争状态而破坏队列。

&emsp;&emsp;锁有多种多样的形式，而且加锁的粒度范围也各不相同，Linux自身实现了几种不同的锁机制。各种锁机制之间的区别主要在于当锁被持有时的行为表现，一些锁被持有时会不断进行循环，等待锁重新可用，而有些锁会使当前任务睡眠，直到锁可用为止。下一节我们将讨论Linux中不同锁之间的行为差别及它们的接口。

### 7.1.3 确定保护对象

&emsp;&emsp;找出哪些数据需要保护是关键所在。由于任何可能被并发访问的代码都需要保护，所以寻找哪些代码不需要保护反而相对更容易些，我们也就从这里入手。内核任务的局部数据仅仅被它本身访问，显然不需要保护，比如，局部自动变量不需要任何形式的锁，因为它们独立存在于内核任务的栈中。类似地，如果数据只会被特定的进程访问，那么也不需要加锁。

&emsp;&emsp;到底什么数据需要加锁呢？大多数内核数据结构都需要加锁！有一条很好的经验可以帮助我们判断：如果有其它内核任务可以访问这些数据，那么就给这些数据加上某种形式的锁；如果任何其它东西能看到它，那么就要锁住它。

### 7.1.4 死锁

&emsp;&emsp;死锁的产生需要一定条件：要有一个或多个并发执行的内核任务和一个或多个资源，每个任务都在等待其中的一个资源，但所有的资源都已经被占用了。所有任务都在相互等待，但它们永远不会释放已经占有的资源。于是任何任务都无法继续，这便意味着死锁发生了。

&emsp;&emsp;一个很好的死锁例子是四路交通堵塞问题。如果每一个停止的车都决心等待其它的车开动后自己再启动，那么就没有任何一俩车能启动，于是交通死锁发生了。

&emsp;&emsp;最简单的死锁例子是 **自死锁**：如果一个执行任务试图去获得一个自己已经持有的锁，它将不得不等待锁被释放，但因为它正在忙着等待这个锁，所以自己永远也不会有机会释放锁，最终结果就是死锁：

    获得锁

    再次试图获得锁

    等待锁重新可用……

&emsp;&emsp;同样道理，考虑 有n个内核任务和n把锁，如果每个任务都持有一把其它进程需要得到的锁，那么所有的任务都将停下来等待它们希望得到的锁重新可用。最常见的例子是有两个任务和两把锁，它们通常被叫做ABBA死锁。

    **内核任务1 内核任务2**

    获得锁 A 获得锁B

    试图获得锁B 试图获得锁 A

    等待锁 B 等待锁 A

&emsp;&emsp;每个任务都在等待其它任务持有的锁，但是绝没有一个任务会释放它们一开始就持有的锁。这种类型的死锁也叫做 _**“致命拥抱”**_。

&emsp;&emsp;预防死锁的发生非常重要，虽然很难证明代码是否隐含着死锁，但是写出避免死锁的代码还是可能的。下面给出的一些简单规则来避免死锁的发生：

1. 加锁的顺序是关键。使用嵌套的锁时必须保证以相同的顺序获取锁，这样可以阻止致命拥抱类型的死锁。最好能记录下锁的顺序，以便其他人也能照此顺序使用。

2. 防止发生饥饿，试着自问，这个代码的执行是否一定会结束？如果  
   “张”不发生？“王”要一直等待下去吗？

3. 不要重复请求同一个锁。

4. 越复杂的加锁方案越有可能造成死锁，因此设计应力求简单

### 7.1.5 并发执行的原因

&emsp;&emsp;用户空间之所以需要同步，是因为用户进程会被调度程序抢占和重新调度。由于用户进程可能在任何时刻被抢占，从而使调度程序完全可能选择另一个高优先级的进程到处理器上执行，所以就有可能在一个进程正处于临界区时，就被非自愿地抢占了，如果新被调度的进程随后也进入同一个临界区，前后两个进程相互之间就会产生竞争。这种类型的并发操作并不是真的同时发生，它们只是相互交叉进行，所以也可称作 **“伪并发”** 执行。

&emsp;&emsp;如果在对称多处理器的机器上，那么两个进程就可以真正地在临界区中同时执行了，这种类型被称为 **“真并发”** 。虽然真并发和伪并发的原因和含义不同，但它们都同样会造成竞争状态，而且也同样需要保护。

&emsp;&emsp;那么，内核中造成并发执行的原因有哪些？简单来说有以下几种：

（1）中断——中断几乎可以在任何时刻异步发生，也就可能随时打断当前正在执行的代码。

（2） 内核抢占——如果内核具有抢占性，那么内核中的任务可能会被另一任务抢占。

（3） 睡眠及与用户空间的同步——在内核执行的进程可能会睡眠，这就会唤醒调度程序，从而导致调度一个新的用户进程执行。

（4）对称多处理——两个或多个处理器可以同时执行代码。

&emsp;&emsp;对内核开发者来说，必须理解上述这些并发执行的诱因，并且为它们事先做充分准备工作。如果在一段内核代码访问某资源的时候系统产生了一个中断，而该中断的处理程序居然还要访问这一资源，这就存在一个“潜在的错误”；类似地，如果一段内核代码在访问一个共享资源期间可以被抢占，这也存在一个“潜在的错误”；还有，如果内核代码在临界区中睡眠，那就是毫无原则地等待竞争状态的到来。最后还要注意，两个处理器绝对不能同时访问同一共享数据。

&emsp;&emsp;当我们清楚什么样的数据需要保护时，用锁来保护代码安全也就不难做到。然而，真正困难的是如何发现上述潜在并发执行的可能，并有意识地采取某些措施来防止并发执行。其实，真正用锁来保护共享资源并不困难，只要在设计代码的早期就这么做，事情就会很简单。但是，辨认出真正需要共享的数据和相应的临界区，才是真正有挑战性的地方。这里要说明的是，最开始设计代码的时候就要考虑加入锁。如果代码已经写好了，再在其中找到需要上锁的部分并向其中追加锁，是非常困难的，结果也往往不尽人意。所以，在编写代码的开始阶段就设计恰当的锁是一种基本原则。

